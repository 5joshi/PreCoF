{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "from pmlb import fetch_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        print(f\"{func.__name__} took {end - start:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def create_classifier(X, y, ignored_features=[]):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)\n",
    "    X_train = X_train.drop(columns=ignored_features)\n",
    "    X_test = X_test.drop(columns=ignored_features)\n",
    "    \n",
    "    numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X_train.select_dtypes(include=['category', 'object']).columns\n",
    "    print(numeric_features, categorical_features)\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('scaler', StandardScaler())])\n",
    "    categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('classifier', DecisionTreeClassifier(random_state=0))])\n",
    "    \n",
    "    param_grid = {\n",
    "        'classifier__max_depth': [5, 10, 20, None],\n",
    "        'classifier__min_samples_split': [2, 5, 10, 20],\n",
    "        'classifier__min_samples_leaf': [1, 5, 10, 20],\n",
    "        'classifier__criterion': ['gini', 'entropy']\n",
    "    }\n",
    "    grid = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    clf = grid.best_estimator_\n",
    "    accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
    "    \n",
    "    return clf, accuracy\n",
    "\n",
    "def get_feature_names(clf):\n",
    "    feature_names = []\n",
    "    for name, transformer, features in clf.named_steps['preprocessor'].transformers_:\n",
    "        if name == 'num':\n",
    "            feature_names.extend(features)\n",
    "        elif name == 'cat':\n",
    "            try:\n",
    "                feature_names.extend(transformer.named_steps['onehot'].get_feature_names_out(features))\n",
    "            except NotFittedError:\n",
    "                print(\"Warning: no categorical features found\")\n",
    "    return feature_names\n",
    "    \n",
    "def calculate_fairness_metrics(clf, X, y, sensitive_attributes, bad_outcome, ignored_features=[]):\n",
    "    X_train, X_test_full, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)\n",
    "    X_test = X_test_full.drop(columns=ignored_features)\n",
    "\n",
    "    good_outcome = not bad_outcome\n",
    "    value_combinations = [*it.product(*[X[sensitive_attribute].unique() for sensitive_attribute in sensitive_attributes])]\n",
    "    metrics = {'TP': {}, 'FP': {}, 'TN': {}, 'FN': {}, 'PPV': {}, 'PR': {}, 'TPR': {}, 'FPR': {}, 'acc': {}, 'balanced_acc': {}}\n",
    "    \n",
    "    for attribute in value_combinations:\n",
    "        for key in ['TP', 'FP', 'TN', 'FN']:\n",
    "            metrics[key][attribute] = 0\n",
    "\n",
    "    for idx in range(len(y_test)):\n",
    "        attribute = tuple(X_test_full.iloc[idx][sensitive_attributes])\n",
    "\n",
    "        prediction = clf.predict(X_test.iloc[idx:idx + 1, :])[0]\n",
    "        actual = y_test.iloc[idx]\n",
    "\n",
    "        if prediction == good_outcome:\n",
    "            if actual == good_outcome:\n",
    "                metrics['TP'][attribute] += 1\n",
    "            else:\n",
    "                metrics['FP'][attribute] += 1\n",
    "        elif prediction == bad_outcome:\n",
    "            if actual == bad_outcome:\n",
    "                metrics['TN'][attribute] += 1\n",
    "            else:\n",
    "                metrics['FN'][attribute] += 1\n",
    "\n",
    "    for attribute in value_combinations:\n",
    "        TP = metrics['TP'][attribute]\n",
    "        FP = metrics['FP'][attribute]\n",
    "        TN = metrics['TN'][attribute]\n",
    "        FN = metrics['FN'][attribute]\n",
    "        \n",
    "        try:\n",
    "            metrics['PPV'][attribute] = TP / (TP + FP)  # Positive Predictive Value\n",
    "            metrics['PR'][attribute] = (TP + FP) / (TP + FP + TN + FN)  # Precision-Recall\n",
    "            metrics['TPR'][attribute] = TP / (TP + FN)  # True Positive Rate\n",
    "            metrics['FPR'][attribute] = FP / (FP + TN)  # False Positive Rate\n",
    "            metrics['balanced_acc'][attribute] = 0.5 * (TP / (TP + FN) + TN / (TN + FP))  \n",
    "            metrics['acc'][attribute] = (TP + TN) / (TP + FP + TN + FN)  \n",
    "        except ZeroDivisionError:\n",
    "            for key in ['PPV', 'PR', 'TPR', 'FPR', 'balanced_acc', 'acc']:\n",
    "                metrics[key][attribute] = 0\n",
    "\n",
    "    for attribute in value_combinations:\n",
    "        print(f\"Group: {attribute}\")\n",
    "        for metric_name, metric_values in metrics.items():\n",
    "            print(f\"  {metric_name}: {metric_values[attribute]}\")\n",
    "        print()\n",
    "\n",
    "    return metrics['PPV'], metrics['PR'], metrics['TPR'], metrics['FPR'], metrics['acc'], metrics['balanced_acc']\n",
    "\n",
    "def calculate_explicit_bias(clf, X, y, sensitive_attributes, bad_outcome):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)\n",
    "    value_combinations = [*it.product(*[X[sensitive_attribute].unique() for sensitive_attribute in sensitive_attributes])]\n",
    "    factual, explanation = [], []\n",
    "\n",
    "    for idx in range(len(y_test)):\n",
    "        to_explain = X_test.iloc[idx:idx+1, :]  \n",
    "        \n",
    "        if clf.predict(to_explain)[0] == bad_outcome:\n",
    "            CF = copy.deepcopy(to_explain)  \n",
    "\n",
    "            # print(f'Instance {idx}', value_combinations)\n",
    "            for values in value_combinations:\n",
    "                # print(CF, values)\n",
    "                CF[sensitive_attributes] = values\n",
    "                # print(CF, clf.predict(CF)[0], bad_outcome)\n",
    "                if clf.predict(CF)[0] != bad_outcome:\n",
    "                    factual_changes = []\n",
    "                    explanation_changes = []\n",
    "\n",
    "                    for attr, original, counterfactual in zip(sensitive_attributes, to_explain.iloc[0][sensitive_attributes], values):\n",
    "                        # print(attr, original, counterfactual, original != counterfactual)\n",
    "                        if original != counterfactual:\n",
    "                            factual_changes.append(original)\n",
    "                            explanation_changes.append(counterfactual)\n",
    "\n",
    "                    factual.append(str(factual_changes))\n",
    "                    explanation.append(str(explanation_changes))\n",
    "                    break  \n",
    "\n",
    "    factual_dict = Counter(factual)\n",
    "    explanation_dict = Counter(explanation)\n",
    "\n",
    "    print(f'Explicit bias detected:\\nFactual Changes: {factual_dict}\\nExplanation Changes: {explanation_dict}')\n",
    "\n",
    "    return factual_dict, explanation_dict\n",
    "\n",
    "\n",
    "def plot_feature_importance(clf, sensitive_attributes, filename):\n",
    "    feature_importances = clf['classifier'].feature_importances_\n",
    "    feature_names = get_feature_names(clf)\n",
    "    \n",
    "    feature_data = pd.DataFrame(zip(feature_names, feature_importances), columns=[\"feature\", \"value\"])\n",
    "    feature_data[\"abs_value\"] = feature_data[\"value\"].abs()\n",
    "    feature_data[\"color\"] = feature_data[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "    feature_data = feature_data.sort_values(\"abs_value\", ascending=False)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    sns.barplot(x=\"feature\", y=\"value\", data=feature_data.head(10), palette='mako', ax=ax)\n",
    "    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=14)\n",
    "    ax.set_title(\"Top 10 Features\", fontsize=20)\n",
    "    ax.set_xlabel(\"Feature Name\", fontsize=16)\n",
    "    ax.set_ylabel(\"Feature Importance\", fontsize=16)\n",
    "    plt.suptitle(f'Sensitive Attributes: {sensitive_attributes}', fontsize=18)\n",
    "    \n",
    "    fig.savefig(f\"{filename}_feature_importance.png\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "def plot_explicit_bias(sensitive_attributes, factual_dict, explanation_dict, filename):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(factual_dict.keys(), factual_dict.values(), label=f'Counterfactual values', color='red')\n",
    "    ax.set_title(f\"Explicit bias with {', '.join(sensitive_attributes)}\", fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    fig.savefig(f\"{filename}_explicit_bias_counterfactual.png\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(explanation_dict.keys(), explanation_dict.values(), label=f'Factual values', color='green')\n",
    "    ax.set_title(f\"Explicit bias with {', '.join(sensitive_attributes)}\", fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    fig.savefig(f\"{filename}_explicit_bias_factual.png\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "@timer\n",
    "def get_counterfactual_counts(clf, X_test, multi_variable=False):    \n",
    "    predictions = clf.predict(X_test)\n",
    "    \n",
    "    X_test_transformed = clf.named_steps['preprocessor'].transform(X_test)\n",
    "    feature_names = get_feature_names(clf)\n",
    "    original_feature_names = X_test.columns.tolist()\n",
    "\n",
    "    counterfactual_counts = defaultdict(int, {feature: 0 for feature in original_feature_names})\n",
    "        \n",
    "    tree = clf.named_steps['classifier']\n",
    "    node_indicator = tree.decision_path(X_test_transformed)\n",
    "    leaf_id = tree.apply(X_test_transformed)\n",
    "    \n",
    "    \n",
    "    for sample_id in range(X_test.shape[0]):\n",
    "        target_class = not predictions[sample_id]\n",
    "        node_index = node_indicator.indices[\n",
    "            node_indicator.indptr[sample_id] : node_indicator.indptr[sample_id + 1]\n",
    "        ]\n",
    "        \n",
    "        single_var_counterfactuals = set()\n",
    "        multi_var_counterfactuals = set()\n",
    "        \n",
    "        for node_id in node_index:\n",
    "            if leaf_id[sample_id] == node_id:\n",
    "                continue\n",
    "            \n",
    "            feature_id = tree.tree_.feature[node_id]\n",
    "            threshold = tree.tree_.threshold[node_id]\n",
    "            \n",
    "            feature_name = feature_names[feature_id]\n",
    "            original_feature_name = max((name for name in original_feature_names if name in feature_name), key=len)\n",
    "            feature_value = X_test_transformed[sample_id, feature_id]\n",
    "            \n",
    "            counterfactual = X_test_transformed[sample_id].copy()\n",
    "            if hasattr(counterfactual, \"toarray\"):\n",
    "                counterfactual = counterfactual.toarray()[0]\n",
    "            \n",
    "            if feature_value <= threshold:\n",
    "                counterfactual[feature_id] = threshold + 0.01\n",
    "            else:\n",
    "                counterfactual[feature_id] = threshold - 0.01\n",
    "            \n",
    "            curr_prediction = tree.predict(counterfactual.reshape(1, -1))[0]\n",
    "            \n",
    "            if curr_prediction == target_class or multi_variable is False:\n",
    "                if curr_prediction == target_class:\n",
    "                    single_var_counterfactuals.add(original_feature_name)\n",
    "                continue\n",
    "            \n",
    "            new_node_index = tree.decision_path(counterfactual.reshape(1, -1)).indices\n",
    "            new_path_nodes = [node for node in new_node_index if node not in node_index]\n",
    "            \n",
    "            for new_node_id in new_path_nodes:\n",
    "                new_feature_id = tree.tree_.feature[new_node_id]\n",
    "                new_threshold = tree.tree_.threshold[new_node_id]\n",
    "                \n",
    "                if new_feature_id == -2 or new_feature_id == feature_id:\n",
    "                    continue\n",
    "                \n",
    "                new_feature_name = feature_names[new_feature_id]\n",
    "                new_original_feature_name = max((name for name in original_feature_names if name in new_feature_name), key=len)\n",
    "                new_feature_value = counterfactual[new_feature_id]\n",
    "                \n",
    "                new_counterfactual = counterfactual.copy()\n",
    "                if new_feature_value <= new_threshold:\n",
    "                    new_counterfactual[new_feature_id] = new_threshold + 0.01\n",
    "                else:\n",
    "                    new_counterfactual[new_feature_id] = new_threshold - 0.01\n",
    "                \n",
    "                new_prediction = tree.predict(new_counterfactual.reshape(1, -1))[0]\n",
    "                if new_prediction == target_class:\n",
    "                    multi_var_counterfactuals.add(tuple(sorted([original_feature_name, new_original_feature_name])))\n",
    "                \n",
    "        for feature in single_var_counterfactuals | multi_var_counterfactuals:\n",
    "            counterfactual_counts[feature] += 1\n",
    "            \n",
    "    return counterfactual_counts\n",
    "\n",
    "@timer\n",
    "def get_counterfactual_counts_old(clf, X_test, default_values):\n",
    "    predictions = clf.predict(X_test)\n",
    "    \n",
    "    feature_names = X_test.columns\n",
    "    counterfactual_counts = defaultdict(int, {feature: 0 for feature in feature_names})\n",
    "        \n",
    "    for sample_id in range(X_test.shape[0]):\n",
    "        instance = X_test.iloc[sample_id:sample_id + 1, :]\n",
    "        target_class = not predictions[sample_id]\n",
    "        \n",
    "        for feature in feature_names:\n",
    "            for val in default_values.get(feature, []):\n",
    "                modified_instance = copy.deepcopy(instance)\n",
    "                modified_instance[feature] = val\n",
    "                \n",
    "                if clf.predict(modified_instance)[0] == target_class:\n",
    "                    counterfactual_counts[feature] += 1\n",
    "                    break\n",
    "            \n",
    "    return counterfactual_counts\n",
    "\n",
    "@timer\n",
    "def get_counterfactual_counts_descriptive(clf, X_test, multi_variable=False):    \n",
    "    predictions = clf.predict(X_test)\n",
    "    \n",
    "    X_test_transformed = clf.named_steps['preprocessor'].transform(X_test)\n",
    "    feature_names = get_feature_names(clf)\n",
    "    original_feature_names = X_test.columns.tolist()\n",
    "    \n",
    "    counterfactual_counts = defaultdict(int)\n",
    "    factual_changes = defaultdict(Counter)\n",
    "    explanation_changes = defaultdict(Counter)\n",
    "        \n",
    "    tree = clf.named_steps['classifier']\n",
    "    node_indicator = tree.decision_path(X_test_transformed)\n",
    "    leaf_id = tree.apply(X_test_transformed)\n",
    "    \n",
    "    \n",
    "    for sample_id in range(X_test.shape[0]):\n",
    "        target_class = not predictions[sample_id]\n",
    "        original_instance = X_test.iloc[sample_id]\n",
    "        \n",
    "        node_index = node_indicator.indices[\n",
    "            node_indicator.indptr[sample_id] : node_indicator.indptr[sample_id + 1]\n",
    "        ]\n",
    "        \n",
    "        single_var_counterfactuals = set()\n",
    "        multi_var_counterfactuals = set()\n",
    "        \n",
    "        curr_factual_changes = defaultdict(list)\n",
    "        curr_explanation_changes = defaultdict(list)\n",
    "        \n",
    "        for node_id in node_index:\n",
    "            if leaf_id[sample_id] == node_id:\n",
    "                continue\n",
    "            \n",
    "            feature_id = tree.tree_.feature[node_id]\n",
    "            threshold = tree.tree_.threshold[node_id]\n",
    "            \n",
    "            feature_name = feature_names[feature_id]\n",
    "            original_feature_name = max((name for name in original_feature_names if name in feature_name), key=len)\n",
    "            feature_value = X_test_transformed[sample_id, feature_id]\n",
    "            \n",
    "            counterfactual = X_test_transformed[sample_id].copy()\n",
    "            if hasattr(counterfactual, \"toarray\"):\n",
    "                counterfactual = counterfactual.toarray()[0]\n",
    "            \n",
    "            if feature_value <= threshold:\n",
    "                counterfactual[feature_id] = threshold + 0.01\n",
    "            else:\n",
    "                counterfactual[feature_id] = threshold - 0.01\n",
    "            \n",
    "            curr_prediction = tree.predict(counterfactual.reshape(1, -1))[0]\n",
    "            \n",
    "            if curr_prediction == target_class:\n",
    "                single_var_counterfactuals.add(original_feature_name)\n",
    "                \n",
    "                original_value = original_instance.get(original_feature_name, None)\n",
    "                explanation_value = f\"{feature_name} {'>' if counterfactual[feature_id] > threshold else '<='} {threshold:.2f}\"\n",
    "                \n",
    "                curr_factual_changes[original_feature_name].append(original_value)\n",
    "                curr_explanation_changes[original_feature_name].append(explanation_value)\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            if not multi_variable: \n",
    "                continue\n",
    "            \n",
    "            new_node_index = tree.decision_path(counterfactual.reshape(1, -1)).indices\n",
    "            new_path_nodes = [node for node in new_node_index if node not in node_index]\n",
    "            \n",
    "            for new_node_id in new_path_nodes:\n",
    "                new_feature_id = tree.tree_.feature[new_node_id]\n",
    "                new_threshold = tree.tree_.threshold[new_node_id]\n",
    "                \n",
    "                if new_feature_id == -2 or new_feature_id == feature_id:\n",
    "                    continue\n",
    "                \n",
    "                new_feature_name = feature_names[new_feature_id]\n",
    "                new_original_feature_name = max((name for name in original_feature_names if name in new_feature_name), key=len)\n",
    "                new_feature_value = counterfactual[new_feature_id]\n",
    "                \n",
    "                new_counterfactual = counterfactual.copy()\n",
    "                if new_feature_value <= new_threshold:\n",
    "                    new_counterfactual[new_feature_id] = new_threshold + 0.01\n",
    "                else:\n",
    "                    new_counterfactual[new_feature_id] = new_threshold - 0.01\n",
    "                \n",
    "                new_prediction = tree.predict(new_counterfactual.reshape(1, -1))[0]\n",
    "                if new_prediction == target_class:\n",
    "                    multi_var_counterfactuals.add(tuple(sorted([original_feature_name, new_original_feature_name])))\n",
    "                    \n",
    "                    original_values = (original_instance.get(original_feature_name, None),\n",
    "                                      original_instance.get(new_original_feature_name, None))\n",
    "                    \n",
    "                    explanation_value = f\"{feature_name} {'>' if counterfactual[feature_id] > threshold else '<='} {threshold:.2f}\"\n",
    "                    new_explanation_value = f\"{new_feature_name} {'>' if new_counterfactual[new_feature_id] > new_threshold else '<='} {new_threshold:.2f}\"\n",
    "\n",
    "                    if sorted([original_feature_name, new_original_feature_name]) == [original_feature_name, new_original_feature_name]:\n",
    "                        curr_factual_changes[tuple(sorted([original_feature_name, new_original_feature_name]))].append(original_values)\n",
    "                        curr_explanation_changes[tuple(sorted([original_feature_name, new_original_feature_name]))].append((explanation_value, new_explanation_value))\n",
    "                    else:\n",
    "                        curr_factual_changes[tuple(sorted([new_original_feature_name, original_feature_name]))].append(original_values[::-1])\n",
    "                        curr_explanation_changes[tuple(sorted([new_original_feature_name, original_feature_name]))].append((new_explanation_value, explanation_value))\n",
    "                \n",
    "        for feature in single_var_counterfactuals | multi_var_counterfactuals:\n",
    "            counterfactual_counts[feature] += 1\n",
    "            factual_changes[feature].update(curr_factual_changes[feature])\n",
    "            explanation_changes[feature].update(curr_explanation_changes[feature])\n",
    "            \n",
    "    return counterfactual_counts, factual_changes, explanation_changes\n",
    "\n",
    "@timer\n",
    "def get_precof_values(clf, X, y, minority_class, minority_value, negative_outcome, method=\"new\", multi_variable=False):\n",
    "    X_test = train_test_split(X, test_size=0.3, stratify=y, random_state=0)[1]\n",
    "    X_negative = X_test[clf.predict(X_test) == negative_outcome]\n",
    "        \n",
    "    X_minority = X_negative[X_negative[minority_class] == minority_value]\n",
    "    X_majority = X_negative[X_negative[minority_class] != minority_value]\n",
    "    \n",
    "    minority_total = X_minority.shape[0]\n",
    "    majority_total = X_majority.shape[0]\n",
    "    \n",
    "    if method == \"new\":\n",
    "        if minority_total > 0:\n",
    "            minority_counts = get_counterfactual_counts(clf, X_minority, multi_variable)\n",
    "        if majority_total > 0:\n",
    "            majority_counts = get_counterfactual_counts(clf, X_majority, multi_variable)\n",
    "    elif method == \"old\":\n",
    "        default_values = calculate_default_values(X, y)\n",
    "        if minority_total > 0:\n",
    "            minority_counts = get_counterfactual_counts_old(clf, X_minority, default_values)\n",
    "        if majority_total > 0:\n",
    "            majority_counts = get_counterfactual_counts_old(clf, X_majority, default_values)\n",
    "    elif method == \"descriptive\":\n",
    "        minority_factual_changes = majority_factual_changes = defaultdict(Counter)\n",
    "        minority_explanation_changes = majority_explanation_changes = defaultdict(Counter)\n",
    "        \n",
    "        if minority_total > 0:\n",
    "            minority_counts, minority_factual_changes, minority_explanation_changes = get_counterfactual_counts_descriptive(clf, X_minority, multi_variable)\n",
    "        if majority_total > 0:\n",
    "            majority_counts, majority_factual_changes, majority_explanation_changes = get_counterfactual_counts_descriptive(clf, X_majority, multi_variable)\n",
    "            \n",
    "    if majority_total == 0:\n",
    "        majority_counts = {feature: 0 for feature in minority_counts.keys()}\n",
    "    elif minority_total == 0:\n",
    "        minority_counts = {feature: 0 for feature in majority_counts.keys()}\n",
    "    \n",
    "    precof_values = {}\n",
    "    features = set(minority_counts.keys()).union(set(majority_counts.keys()))\n",
    "    \n",
    "    for feature in features:\n",
    "        minority_value = minority_counts.get(feature, 0) / minority_total if minority_total > 0 else 0\n",
    "        majority_value = majority_counts.get(feature, 0) / majority_total if majority_total > 0 else 0\n",
    "        \n",
    "        precof = minority_value - majority_value\n",
    "        precof_values[feature] = precof\n",
    "        \n",
    "    if method != \"descriptive\":\n",
    "        return precof_values\n",
    "    else:    \n",
    "        return precof_values, minority_factual_changes, minority_explanation_changes, majority_factual_changes, majority_explanation_changes\n",
    "\n",
    "def calculate_default_values(X, y):\n",
    "    X_train, *_ = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)\n",
    "    \n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['category', 'object']).columns\n",
    "    \n",
    "    default_values = {}\n",
    "    threshold = len(X_train) / 100\n",
    "    \n",
    "    for feature in numeric_features:\n",
    "        default_values[feature] = [*{*np.percentile(X_train[feature], [10, 20, 30, 40, 50, 60, 70, 80, 90, 100])}]  # Deduplicate\n",
    "    for feature in categorical_features:\n",
    "        default_values[feature] = []\n",
    "        value_counts = X_train[feature].value_counts()\n",
    "        for val, count in value_counts.items():\n",
    "            if count < threshold: break\n",
    "            default_values[feature].append(val)\n",
    "            \n",
    "        if len(default_values[feature]) == 0 or len(default_values[feature]) > 10:\n",
    "            default_values[feature] = value_counts.index[:10].tolist()\n",
    "          \n",
    "    return default_values\n",
    "\n",
    "def full_precof_analysis(X, y, sensitive_attributes, minority_class, minority_value, negative_outcome, name):\n",
    "    clf, accuracy = create_classifier(X, y)\n",
    "    \n",
    "    precof_values = get_precof_values(clf, X, y, minority_class, minority_value, negative_outcome, method=\"new\")\n",
    "    multi_var_precof_values = get_precof_values(clf, X, y, minority_class, minority_value, negative_outcome, method=\"new\", multi_variable=True)\n",
    "    old_precof_values = get_precof_values(clf, X, y, minority_class, minority_value, negative_outcome, method=\"old\")\n",
    "    fairness_metrics = calculate_fairness_metrics(clf, X, y, sensitive_attributes, negative_outcome)\n",
    "    factual_dict, explanation_dict = calculate_explicit_bias(clf, X, y, sensitive_attributes, negative_outcome)\n",
    "\n",
    "    plot_feature_importance(clf, sensitive_attributes, f\"{name}_full\")\n",
    "    plot_explicit_bias(sensitive_attributes, factual_dict, explanation_dict, f\"{name}_full\")\n",
    "    \n",
    "    print(\"Model with sensitive attributes\")\n",
    "    print(\"=======================\")\n",
    "    print(f\"Classifier Accuracy: {accuracy:.4f}\\n\")\n",
    "    \n",
    "    print(f\"Fairness Metrics: {fairness_metrics}\")\n",
    "    print(f'Explicit bias detected:\\nFactual Changes: {factual_dict}\\nExplanation Changes: {explanation_dict}')\n",
    "    print(f\"PreCoF Values: {sorted(precof_values.items(), key=lambda x: x[1], reverse=True)}\")\n",
    "    print(f\"Multi-Variable PreCoF Values: {sorted(multi_var_precof_values.items(), key=lambda x: x[1], reverse=True)}\")\n",
    "    print(f\"Old PreCoF Values: {sorted(old_precof_values.items(), key=lambda x: x[1], reverse=True)}\")\n",
    "    \n",
    "    clf, accuracy = create_classifier(X, y, ignored_features=sensitive_attributes)\n",
    "\n",
    "    precof_values = get_precof_values(clf, X, y, minority_class, minority_value, negative_outcome, method=\"new\")\n",
    "    multi_var_precof_values = get_precof_values(clf, X, y, minority_class, minority_value, negative_outcome, method=\"new\", multi_variable=True)\n",
    "    old_precof_values = get_precof_values(clf, X, y, minority_class, minority_value, negative_outcome, method=\"old\")\n",
    "    fairness_metrics = calculate_fairness_metrics(clf, X, y, sensitive_attributes, negative_outcome)\n",
    "    \n",
    "    plot_feature_importance(clf, sensitive_attributes, f\"{name}_no_sensitive\")\n",
    "    \n",
    "    print(\"\\nModel without sensitive attributes\")\n",
    "    print(\"=======================\")\n",
    "    print(f\"Classifier Accuracy: {accuracy:.4f}\\n\")\n",
    "    \n",
    "    print(f\"Fairness Metrics: {fairness_metrics}\")\n",
    "    print(f\"PreCoF Values: {sorted(precof_values.items(), key=lambda x: x[1], reverse=True)}\")\n",
    "    print(f\"Multi-Variable PreCoF Values: {sorted(multi_var_precof_values.items(), key=lambda x: x[1], reverse=True)}\")\n",
    "    print(f\"Old PreCoF Values: {sorted(old_precof_values.items(), key=lambda x: x[1], reverse=True)}\")\n",
    "\n",
    "def precof_analysis(X, y, sensitive_attributes, minority_class, minority_value, negative_outcome, name):\n",
    "    clf, accuracy = create_classifier(X, y, ignored_features=sensitive_attributes)\n",
    "\n",
    "    precof_values, minority_factual_changes, minority_explanation_changes, majority_factual_changes, majority_explanation_changes = get_precof_values(clf, X, y, minority_class, minority_value, negative_outcome, method=\"descriptive\", multi_variable=True)\n",
    "    \n",
    "    print(\"\\nModel without sensitive attributes\")\n",
    "    print(\"=======================\")\n",
    "    print(f\"Classifier Accuracy: {accuracy:.4f}\\n\")\n",
    "    \n",
    "    def print_changes(changes, top_precof=3, top_n=2):\n",
    "        sorted_changes = sorted(changes.items(), key=lambda x: precof_values[x[0]], reverse=True)\n",
    "        for i, (feature, values) in enumerate(sorted_changes[:min(top_precof, len(sorted_changes))]):\n",
    "            print(f\"Rank {i + 1} | {feature} (PreCoF: {precof_values[feature]:.4f}): {values.most_common()[:(min(top_n, len(values)))]}\")\n",
    "        for i, (feature, values) in enumerate(sorted_changes[-min(top_precof, len(sorted_changes)):]):\n",
    "            print(f\"Rank -{min(top_precof, len(sorted_changes)) - i} | {feature} (PreCoF: {precof_values[feature]:.4f}): {values.most_common()[:(min(top_n, len(values)))]}\")\n",
    "            \n",
    "    print(f\"Multi-Variable PreCoF Values:\")\n",
    "    pprint(sorted(precof_values.items(), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    print(\"Minority Factual Changes: \")\n",
    "    print_changes(minority_factual_changes)\n",
    "    print(\"Minority Explanation Changes: \")\n",
    "    print_changes(minority_explanation_changes)\n",
    "    print(\"Majority Factual Changes: \")\n",
    "    print_changes(majority_factual_changes)\n",
    "    print(\"Majority Explanation Changes: \")\n",
    "    print_changes(majority_explanation_changes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
      "       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences'],\n",
      "      dtype='object') Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
      "       'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
      "       'nursery', 'higher', 'internet', 'romantic'],\n",
      "      dtype='object')\n",
      "get_counterfactual_counts took 0.0214 seconds\n",
      "get_counterfactual_counts took 0.0148 seconds\n",
      "get_precof_values took 0.0424 seconds\n",
      "get_counterfactual_counts took 0.0574 seconds\n",
      "get_counterfactual_counts took 0.0352 seconds\n",
      "get_precof_values took 0.0982 seconds\n",
      "get_counterfactual_counts_old took 20.2563 seconds\n",
      "get_counterfactual_counts_old took 11.9696 seconds\n",
      "get_precof_values took 32.2409 seconds\n",
      "Group: ('F', 'mother')\n",
      "  TP: 37\n",
      "  FP: 6\n",
      "  TN: 20\n",
      "  FN: 15\n",
      "  PPV: 0.8604651162790697\n",
      "  PR: 0.5512820512820513\n",
      "  TPR: 0.7115384615384616\n",
      "  FPR: 0.23076923076923078\n",
      "  acc: 0.7307692307692307\n",
      "  balanced_acc: 0.7403846153846154\n",
      "\n",
      "Group: ('F', 'father')\n",
      "  TP: 10\n",
      "  FP: 2\n",
      "  TN: 8\n",
      "  FN: 6\n",
      "  PPV: 0.8333333333333334\n",
      "  PR: 0.46153846153846156\n",
      "  TPR: 0.625\n",
      "  FPR: 0.2\n",
      "  acc: 0.6923076923076923\n",
      "  balanced_acc: 0.7125\n",
      "\n",
      "Group: ('F', 'other')\n",
      "  TP: 1\n",
      "  FP: 2\n",
      "  TN: 4\n",
      "  FN: 2\n",
      "  PPV: 0.3333333333333333\n",
      "  PR: 0.3333333333333333\n",
      "  TPR: 0.3333333333333333\n",
      "  FPR: 0.3333333333333333\n",
      "  acc: 0.5555555555555556\n",
      "  balanced_acc: 0.5\n",
      "\n",
      "Group: ('M', 'mother')\n",
      "  TP: 21\n",
      "  FP: 18\n",
      "  TN: 18\n",
      "  FN: 2\n",
      "  PPV: 0.5384615384615384\n",
      "  PR: 0.6610169491525424\n",
      "  TPR: 0.9130434782608695\n",
      "  FPR: 0.5\n",
      "  acc: 0.6610169491525424\n",
      "  balanced_acc: 0.7065217391304348\n",
      "\n",
      "Group: ('M', 'father')\n",
      "  TP: 7\n",
      "  FP: 3\n",
      "  TN: 5\n",
      "  FN: 3\n",
      "  PPV: 0.7\n",
      "  PR: 0.5555555555555556\n",
      "  TPR: 0.7\n",
      "  FPR: 0.375\n",
      "  acc: 0.6666666666666666\n",
      "  balanced_acc: 0.6625\n",
      "\n",
      "Group: ('M', 'other')\n",
      "  TP: 0\n",
      "  FP: 1\n",
      "  TN: 3\n",
      "  FN: 1\n",
      "  PPV: 0.0\n",
      "  PR: 0.2\n",
      "  TPR: 0.0\n",
      "  FPR: 0.25\n",
      "  acc: 0.6\n",
      "  balanced_acc: 0.375\n",
      "\n",
      "Explicit bias detected:\n",
      "Factual Changes: Counter()\n",
      "Explanation Changes: Counter()\n",
      "Model with sensitive attributes\n",
      "=======================\n",
      "Classifier Accuracy: 0.6872\n",
      "\n",
      "Fairness Metrics: ({('F', 'mother'): 0.8604651162790697, ('F', 'father'): 0.8333333333333334, ('F', 'other'): 0.3333333333333333, ('M', 'mother'): 0.5384615384615384, ('M', 'father'): 0.7, ('M', 'other'): 0.0}, {('F', 'mother'): 0.5512820512820513, ('F', 'father'): 0.46153846153846156, ('F', 'other'): 0.3333333333333333, ('M', 'mother'): 0.6610169491525424, ('M', 'father'): 0.5555555555555556, ('M', 'other'): 0.2}, {('F', 'mother'): 0.7115384615384616, ('F', 'father'): 0.625, ('F', 'other'): 0.3333333333333333, ('M', 'mother'): 0.9130434782608695, ('M', 'father'): 0.7, ('M', 'other'): 0.0}, {('F', 'mother'): 0.23076923076923078, ('F', 'father'): 0.2, ('F', 'other'): 0.3333333333333333, ('M', 'mother'): 0.5, ('M', 'father'): 0.375, ('M', 'other'): 0.25}, {('F', 'mother'): 0.7307692307692307, ('F', 'father'): 0.6923076923076923, ('F', 'other'): 0.5555555555555556, ('M', 'mother'): 0.6610169491525424, ('M', 'father'): 0.6666666666666666, ('M', 'other'): 0.6}, {('F', 'mother'): 0.7403846153846154, ('F', 'father'): 0.7125, ('F', 'other'): 0.5, ('M', 'mother'): 0.7065217391304348, ('M', 'father'): 0.6625, ('M', 'other'): 0.375})\n",
      "Explicit bias detected:\n",
      "Factual Changes: Counter()\n",
      "Explanation Changes: Counter()\n",
      "PreCoF Values: [('school', 0.13636363636363635), ('Fedu', 0.07443181818181815), ('health', 0.0), ('Fjob', 0.0), ('famsize', 0.0), ('Medu', 0.0), ('nursery', 0.0), ('higher', 0.0), ('paid', 0.0), ('traveltime', 0.0), ('sex', 0.0), ('studytime', 0.0), ('guardian', 0.0), ('activities', 0.0), ('freetime', 0.0), ('goout', 0.0), ('Pstatus', 0.0), ('romantic', 0.0), ('address', 0.0), ('internet', 0.0), ('reason', 0.0), ('famsup', 0.0), ('famrel', 0.0), ('failures', -0.015909090909090914), ('schoolsup', -0.026136363636363638), ('age', -0.026136363636363638), ('Mjob', -0.04431818181818182), ('Walc', -0.14602272727272728), ('Dalc', -0.15113636363636362), ('absences', -0.15113636363636362)]\n",
      "Multi-Variable PreCoF Values: [('school', 0.13636363636363635), ('Fedu', 0.07443181818181815), (('Fedu', 'Mjob'), 0.06988636363636364), (('failures', 'school'), 0.05170454545454545), (('age', 'school'), 0.03636363636363636), (('Mjob', 'school'), 0.03636363636363636), (('school', 'schoolsup'), 0.03636363636363636), (('Fedu', 'Fjob'), 0.03636363636363636), (('Fedu', 'failures'), 0.02840909090909091), (('Fjob', 'Mjob'), 0.01818181818181818), ('health', 0.0), ('famsize', 0.0), ('nursery', 0.0), ('paid', 0.0), ('activities', 0.0), ('freetime', 0.0), ('Pstatus', 0.0), ('romantic', 0.0), ('internet', 0.0), ('famrel', 0.0), ('Fjob', 0.0), ('Medu', 0.0), ('higher', 0.0), ('traveltime', 0.0), ('sex', 0.0), ('studytime', 0.0), ('guardian', 0.0), ('goout', 0.0), ('address', 0.0), ('reason', 0.0), ('famsup', 0.0), (('Fedu', 'school'), -0.013068181818181819), ('failures', -0.015909090909090914), ('age', -0.026136363636363638), ('schoolsup', -0.026136363636363638), (('Dalc', 'Walc'), -0.03125), (('absences', 'failures'), -0.03125), (('Walc', 'absences'), -0.03125), (('Dalc', 'failures'), -0.03125), (('Walc', 'failures'), -0.03125), ('Mjob', -0.04431818181818182), ('Walc', -0.14602272727272728), ('Dalc', -0.15113636363636362), (('Walc', 'school'), -0.15113636363636362), ('absences', -0.15113636363636362), (('Dalc', 'school'), -0.1693181818181818), (('absences', 'school'), -0.1693181818181818)]\n",
      "Old PreCoF Values: [('school', 0.13636363636363635), ('Fedu', 0.07443181818181815), ('health', 0.0), ('Fjob', 0.0), ('famsize', 0.0), ('Medu', 0.0), ('nursery', 0.0), ('higher', 0.0), ('paid', 0.0), ('traveltime', 0.0), ('sex', 0.0), ('studytime', 0.0), ('guardian', 0.0), ('activities', 0.0), ('freetime', 0.0), ('goout', 0.0), ('Pstatus', 0.0), ('romantic', 0.0), ('address', 0.0), ('internet', 0.0), ('reason', 0.0), ('famsup', 0.0), ('famrel', 0.0), ('failures', -0.015909090909090914), ('schoolsup', -0.026136363636363638), ('age', -0.026136363636363638), ('Mjob', -0.04431818181818182), ('Walc', -0.14602272727272728), ('Dalc', -0.15113636363636362), ('absences', -0.15113636363636362)]\n",
      "Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
      "       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences'],\n",
      "      dtype='object') Index(['school', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason',\n",
      "       'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher',\n",
      "       'internet', 'romantic'],\n",
      "      dtype='object')\n",
      "get_counterfactual_counts took 0.0230 seconds\n",
      "get_counterfactual_counts took 0.0166 seconds\n",
      "get_precof_values took 0.0453 seconds\n",
      "get_counterfactual_counts took 0.0655 seconds\n",
      "get_counterfactual_counts took 0.0384 seconds\n",
      "get_precof_values took 0.1091 seconds\n",
      "get_counterfactual_counts_old took 19.7831 seconds\n",
      "get_counterfactual_counts_old took 11.3309 seconds\n",
      "get_precof_values took 31.1305 seconds\n",
      "Group: ('F', 'mother')\n",
      "  TP: 37\n",
      "  FP: 6\n",
      "  TN: 20\n",
      "  FN: 15\n",
      "  PPV: 0.8604651162790697\n",
      "  PR: 0.5512820512820513\n",
      "  TPR: 0.7115384615384616\n",
      "  FPR: 0.23076923076923078\n",
      "  acc: 0.7307692307692307\n",
      "  balanced_acc: 0.7403846153846154\n",
      "\n",
      "Group: ('F', 'father')\n",
      "  TP: 10\n",
      "  FP: 2\n",
      "  TN: 8\n",
      "  FN: 6\n",
      "  PPV: 0.8333333333333334\n",
      "  PR: 0.46153846153846156\n",
      "  TPR: 0.625\n",
      "  FPR: 0.2\n",
      "  acc: 0.6923076923076923\n",
      "  balanced_acc: 0.7125\n",
      "\n",
      "Group: ('F', 'other')\n",
      "  TP: 1\n",
      "  FP: 2\n",
      "  TN: 4\n",
      "  FN: 2\n",
      "  PPV: 0.3333333333333333\n",
      "  PR: 0.3333333333333333\n",
      "  TPR: 0.3333333333333333\n",
      "  FPR: 0.3333333333333333\n",
      "  acc: 0.5555555555555556\n",
      "  balanced_acc: 0.5\n",
      "\n",
      "Group: ('M', 'mother')\n",
      "  TP: 21\n",
      "  FP: 18\n",
      "  TN: 18\n",
      "  FN: 2\n",
      "  PPV: 0.5384615384615384\n",
      "  PR: 0.6610169491525424\n",
      "  TPR: 0.9130434782608695\n",
      "  FPR: 0.5\n",
      "  acc: 0.6610169491525424\n",
      "  balanced_acc: 0.7065217391304348\n",
      "\n",
      "Group: ('M', 'father')\n",
      "  TP: 7\n",
      "  FP: 3\n",
      "  TN: 5\n",
      "  FN: 3\n",
      "  PPV: 0.7\n",
      "  PR: 0.5555555555555556\n",
      "  TPR: 0.7\n",
      "  FPR: 0.375\n",
      "  acc: 0.6666666666666666\n",
      "  balanced_acc: 0.6625\n",
      "\n",
      "Group: ('M', 'other')\n",
      "  TP: 0\n",
      "  FP: 1\n",
      "  TN: 3\n",
      "  FN: 1\n",
      "  PPV: 0.0\n",
      "  PR: 0.2\n",
      "  TPR: 0.0\n",
      "  FPR: 0.25\n",
      "  acc: 0.6\n",
      "  balanced_acc: 0.375\n",
      "\n",
      "\n",
      "Model without sensitive attributes\n",
      "=======================\n",
      "Classifier Accuracy: 0.6872\n",
      "\n",
      "Fairness Metrics: ({('F', 'mother'): 0.8604651162790697, ('F', 'father'): 0.8333333333333334, ('F', 'other'): 0.3333333333333333, ('M', 'mother'): 0.5384615384615384, ('M', 'father'): 0.7, ('M', 'other'): 0.0}, {('F', 'mother'): 0.5512820512820513, ('F', 'father'): 0.46153846153846156, ('F', 'other'): 0.3333333333333333, ('M', 'mother'): 0.6610169491525424, ('M', 'father'): 0.5555555555555556, ('M', 'other'): 0.2}, {('F', 'mother'): 0.7115384615384616, ('F', 'father'): 0.625, ('F', 'other'): 0.3333333333333333, ('M', 'mother'): 0.9130434782608695, ('M', 'father'): 0.7, ('M', 'other'): 0.0}, {('F', 'mother'): 0.23076923076923078, ('F', 'father'): 0.2, ('F', 'other'): 0.3333333333333333, ('M', 'mother'): 0.5, ('M', 'father'): 0.375, ('M', 'other'): 0.25}, {('F', 'mother'): 0.7307692307692307, ('F', 'father'): 0.6923076923076923, ('F', 'other'): 0.5555555555555556, ('M', 'mother'): 0.6610169491525424, ('M', 'father'): 0.6666666666666666, ('M', 'other'): 0.6}, {('F', 'mother'): 0.7403846153846154, ('F', 'father'): 0.7125, ('F', 'other'): 0.5, ('M', 'mother'): 0.7065217391304348, ('M', 'father'): 0.6625, ('M', 'other'): 0.375})\n",
      "PreCoF Values: [('school', 0.13636363636363635), ('Fedu', 0.07443181818181815), ('health', 0.0), ('Fjob', 0.0), ('famsize', 0.0), ('Medu', 0.0), ('nursery', 0.0), ('higher', 0.0), ('paid', 0.0), ('traveltime', 0.0), ('sex', 0.0), ('studytime', 0.0), ('guardian', 0.0), ('activities', 0.0), ('freetime', 0.0), ('goout', 0.0), ('Pstatus', 0.0), ('romantic', 0.0), ('address', 0.0), ('internet', 0.0), ('reason', 0.0), ('famsup', 0.0), ('famrel', 0.0), ('failures', -0.015909090909090914), ('schoolsup', -0.026136363636363638), ('age', -0.026136363636363638), ('Mjob', -0.04431818181818182), ('Walc', -0.14602272727272728), ('Dalc', -0.15113636363636362), ('absences', -0.15113636363636362)]\n",
      "Multi-Variable PreCoF Values: [('school', 0.13636363636363635), ('Fedu', 0.07443181818181815), (('Fedu', 'Mjob'), 0.06988636363636364), (('failures', 'school'), 0.05170454545454545), (('age', 'school'), 0.03636363636363636), (('Mjob', 'school'), 0.03636363636363636), (('school', 'schoolsup'), 0.03636363636363636), (('Fedu', 'Fjob'), 0.03636363636363636), (('Fedu', 'failures'), 0.02840909090909091), (('Fjob', 'Mjob'), 0.01818181818181818), ('health', 0.0), ('famsize', 0.0), ('nursery', 0.0), ('paid', 0.0), ('activities', 0.0), ('freetime', 0.0), ('Pstatus', 0.0), ('romantic', 0.0), ('internet', 0.0), ('famrel', 0.0), ('Fjob', 0.0), ('Medu', 0.0), ('higher', 0.0), ('traveltime', 0.0), ('sex', 0.0), ('studytime', 0.0), ('guardian', 0.0), ('goout', 0.0), ('address', 0.0), ('reason', 0.0), ('famsup', 0.0), (('Fedu', 'school'), -0.013068181818181819), ('failures', -0.015909090909090914), ('age', -0.026136363636363638), ('schoolsup', -0.026136363636363638), (('Dalc', 'Walc'), -0.03125), (('absences', 'failures'), -0.03125), (('Walc', 'absences'), -0.03125), (('Dalc', 'failures'), -0.03125), (('Walc', 'failures'), -0.03125), ('Mjob', -0.04431818181818182), ('Walc', -0.14602272727272728), ('Dalc', -0.15113636363636362), (('Walc', 'school'), -0.15113636363636362), ('absences', -0.15113636363636362), (('Dalc', 'school'), -0.1693181818181818), (('absences', 'school'), -0.1693181818181818)]\n",
      "Old PreCoF Values: [('school', 0.13636363636363635), ('Fedu', 0.07443181818181815), ('health', 0.0), ('Fjob', 0.0), ('famsize', 0.0), ('Medu', 0.0), ('nursery', 0.0), ('higher', 0.0), ('paid', 0.0), ('traveltime', 0.0), ('sex', 0.0), ('studytime', 0.0), ('guardian', 0.0), ('activities', 0.0), ('freetime', 0.0), ('goout', 0.0), ('Pstatus', 0.0), ('romantic', 0.0), ('address', 0.0), ('internet', 0.0), ('reason', 0.0), ('famsup', 0.0), ('famrel', 0.0), ('failures', -0.015909090909090914), ('schoolsup', -0.026136363636363638), ('age', -0.026136363636363638), ('Mjob', -0.04431818181818182), ('Walc', -0.14602272727272728), ('Dalc', -0.15113636363636362), ('absences', -0.15113636363636362)]\n"
     ]
    }
   ],
   "source": [
    "student = pd.read_csv('DATA/student/student-por.csv', sep=';')\n",
    "\n",
    "X = student.drop(columns=['G1', 'G2', 'G3'])  \n",
    "y = student['G3'] >= student['G3'].mean()  \n",
    "\n",
    "full_precof_analysis(X, y, ['sex', 'guardian'], 'sex', 'F', False, 'student_por')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
      "       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences'],\n",
      "      dtype='object') Index(['school', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason',\n",
      "       'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher',\n",
      "       'internet', 'romantic'],\n",
      "      dtype='object')\n",
      "get_counterfactual_counts_descriptive took 0.0747 seconds\n",
      "get_counterfactual_counts_descriptive took 0.0426 seconds\n",
      "get_precof_values took 0.1229 seconds\n",
      "\n",
      "Model without sensitive attributes\n",
      "=======================\n",
      "Classifier Accuracy: 0.6872\n",
      "\n",
      "Multi-Variable PreCoF Values:\n",
      "[('school', 0.13636363636363635),\n",
      " ('Fedu', 0.07443181818181815),\n",
      " (('Fedu', 'Mjob'), 0.06988636363636364),\n",
      " (('failures', 'school'), 0.05170454545454545),\n",
      " (('Mjob', 'school'), 0.03636363636363636),\n",
      " (('age', 'school'), 0.03636363636363636),\n",
      " (('school', 'schoolsup'), 0.03636363636363636),\n",
      " (('Fedu', 'Fjob'), 0.03636363636363636),\n",
      " (('Fedu', 'failures'), 0.02840909090909091),\n",
      " (('Fjob', 'Mjob'), 0.01818181818181818),\n",
      " (('Fedu', 'school'), -0.013068181818181819),\n",
      " ('failures', -0.015909090909090914),\n",
      " ('schoolsup', -0.026136363636363638),\n",
      " ('age', -0.026136363636363638),\n",
      " (('Dalc', 'Walc'), -0.03125),\n",
      " (('absences', 'failures'), -0.03125),\n",
      " (('Dalc', 'failures'), -0.03125),\n",
      " (('Walc', 'failures'), -0.03125),\n",
      " (('Walc', 'absences'), -0.03125),\n",
      " ('Mjob', -0.04431818181818182),\n",
      " ('Walc', -0.14602272727272728),\n",
      " ('Dalc', -0.15113636363636362),\n",
      " ('absences', -0.15113636363636362),\n",
      " (('Walc', 'school'), -0.15113636363636362),\n",
      " (('absences', 'school'), -0.1693181818181818),\n",
      " (('Dalc', 'school'), -0.1693181818181818)]\n",
      "Minority Factual Changes: \n",
      "Rank 1 | school (PreCoF: 0.1364): [('MS', 34), ('GP', 1)]\n",
      "Rank 2 | Fedu (PreCoF: 0.0744): [(2, 16), (1, 7)]\n",
      "Rank 3 | ('Fedu', 'Mjob') (PreCoF: 0.0699): [((2, 'at_home'), 5), ((1, 'at_home'), 4)]\n",
      "Rank -3 | Dalc (PreCoF: -0.1511): [(2, 2)]\n",
      "Rank -2 | ('absences', 'school') (PreCoF: -0.1693): [((5, 'MS'), 1)]\n",
      "Rank -1 | ('Dalc', 'school') (PreCoF: -0.1693): [((3, 'MS'), 1)]\n",
      "Minority Explanation Changes: \n",
      "Rank 1 | school (PreCoF: 0.1364): [('school_GP > 0.50', 34), ('school_GP <= 0.50', 1)]\n",
      "Rank 2 | Fedu (PreCoF: 0.0744): [('Fedu > 0.16', 23)]\n",
      "Rank 3 | ('Fedu', 'Mjob') (PreCoF: 0.0699): [(('Fedu > 0.16', 'Mjob_at_home <= 0.50'), 9)]\n",
      "Rank -3 | Dalc (PreCoF: -0.1511): [('Dalc <= -0.01', 2)]\n",
      "Rank -2 | ('absences', 'school') (PreCoF: -0.1693): [(('absences <= -0.58', 'school_GP > 0.50'), 1)]\n",
      "Rank -1 | ('Dalc', 'school') (PreCoF: -0.1693): [(('Dalc <= -0.01', 'school_GP > 0.50'), 1)]\n",
      "Majority Factual Changes: \n",
      "Rank 1 | school (PreCoF: 0.1364): [('MS', 10), ('GP', 6)]\n",
      "Rank 2 | Fedu (PreCoF: 0.0744): [(1, 7), (2, 4)]\n",
      "Rank 3 | ('Fedu', 'Mjob') (PreCoF: 0.0699): [((2, 'at_home'), 2), ((1, 'at_home'), 1)]\n",
      "Rank -3 | Dalc (PreCoF: -0.1511): [(2, 3), (5, 1)]\n",
      "Rank -2 | ('absences', 'school') (PreCoF: -0.1693): [((8, 'MS'), 4), ((2, 'MS'), 1)]\n",
      "Rank -1 | ('Dalc', 'school') (PreCoF: -0.1693): [((5, 'MS'), 3), ((3, 'MS'), 2)]\n",
      "Majority Explanation Changes: \n",
      "Rank 1 | school (PreCoF: 0.1364): [('school_GP > 0.50', 10), ('school_GP <= 0.50', 6)]\n",
      "Rank 2 | Fedu (PreCoF: 0.0744): [('Fedu > 0.16', 11)]\n",
      "Rank 3 | ('Fedu', 'Mjob') (PreCoF: 0.0699): [(('Fedu > 0.16', 'Mjob_at_home <= 0.50'), 3)]\n",
      "Rank -3 | Dalc (PreCoF: -0.1511): [('Dalc <= -0.01', 6)]\n",
      "Rank -2 | ('absences', 'school') (PreCoF: -0.1693): [(('absences <= -0.58', 'school_GP > 0.50'), 6)]\n",
      "Rank -1 | ('Dalc', 'school') (PreCoF: -0.1693): [(('Dalc <= -0.01', 'school_GP > 0.50'), 6)]\n"
     ]
    }
   ],
   "source": [
    "student = pd.read_csv('DATA/student/student-por.csv', sep=';')\n",
    "\n",
    "X = student.drop(columns=['G1', 'G2', 'G3'])  \n",
    "y = student['G3'] >= student['G3'].mean()  \n",
    "\n",
    "precof_analysis(X, y, ['sex', 'guardian'], 'sex', 'F', False, 'student_por')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'education-num', 'capital-gain', 'capital-loss',\n",
      "       'hours-per-week'],\n",
      "      dtype='object') Index(['workclass', 'education', 'marital-status', 'occupation',\n",
      "       'relationship', 'race'],\n",
      "      dtype='object')\n",
      "get_counterfactual_counts_descriptive took 22.6244 seconds\n",
      "get_counterfactual_counts_descriptive took 36.6563 seconds\n",
      "get_precof_values took 59.3097 seconds\n",
      "\n",
      "Model without sensitive attributes\n",
      "=======================\n",
      "Classifier Accuracy: 0.8583\n",
      "\n",
      "Multi-Variable PreCoF Values:\n",
      "[(('capital-loss', 'education-num'), 0.19389486943572792),\n",
      " (('marital-status', 'occupation'), 0.1006464825591975),\n",
      " (('age', 'capital-loss'), 0.09990447433665157),\n",
      " (('education-num', 'marital-status'), 0.09759441355333509),\n",
      " ('marital-status', 0.08242941372327213),\n",
      " (('age', 'hours-per-week'), 0.05703646066589449),\n",
      " (('capital-loss', 'hours-per-week'), 0.03788251245728641),\n",
      " (('hours-per-week', 'marital-status'), 0.013314701417635733),\n",
      " (('marital-status', 'workclass'), 0.011981071722147848),\n",
      " (('marital-status', 'relationship'), 0.005653007840262804),\n",
      " (('education', 'marital-status'), 0.004560688723189425),\n",
      " (('education-num', 'hours-per-week'), 0.0035024171662263875),\n",
      " (('education', 'workclass'), 0.000260860855863023),\n",
      " ('race', 0.0002222716159146477),\n",
      " (('age', 'marital-status'), 6.899744071828945e-05),\n",
      " ('capital-gain', 0.0),\n",
      " (('education', 'hours-per-week'), -4.8364378672632435e-05),\n",
      " (('capital-loss', 'education'), -0.00013531799729364006),\n",
      " (('capital-loss', 'relationship'), -0.00013531799729364006),\n",
      " (('capital-loss', 'workclass'), -0.00013531799729364006),\n",
      " (('capital-gain', 'workclass'), -0.00027063599458728013),\n",
      " (('occupation', 'race'), -0.00027063599458728013),\n",
      " (('education-num', 'race'), -0.00040595399188092014),\n",
      " (('capital-gain', 'occupation'), -0.00040595399188092014),\n",
      " (('capital-gain', 'capital-loss'), -0.0005412719891745603),\n",
      " (('capital-gain', 'hours-per-week'), -0.0007249543651408326),\n",
      " (('capital-loss', 'occupation'), -0.0012276371143670175),\n",
      " ('relationship', -0.002571041948579161),\n",
      " (('education', 'education-num'), -0.0031123139377537213),\n",
      " (('occupation', 'occupation'), -0.0035666323083072735),\n",
      " ('education', -0.003634546964428421),\n",
      " (('education-num', 'relationship'), -0.003924733236464214),\n",
      " ('hours-per-week', -0.004285390739364424),\n",
      " (('age', 'education'), -0.006785450142130517),\n",
      " (('hours-per-week', 'relationship'), -0.007694086883237623),\n",
      " (('age', 'relationship'), -0.007752737715583166),\n",
      " (('education', 'occupation'), -0.008815731416483771),\n",
      " (('age', 'workclass'), -0.011426385234908616),\n",
      " (('hours-per-week', 'workclass'), -0.013310039428398012),\n",
      " ('workclass', -0.024049036908216862),\n",
      " ('age', -0.025908478835020017),\n",
      " ('capital-loss', -0.02931365592895252),\n",
      " (('hours-per-week', 'occupation'), -0.034457153461557095),\n",
      " (('education-num', 'workclass'), -0.045005821471077165),\n",
      " (('age', 'education-num'), -0.051328651894076),\n",
      " (('occupation', 'workclass'), -0.060354383367706724),\n",
      " (('capital-loss', 'marital-status'), -0.06328115013379909),\n",
      " (('capital-gain', 'marital-status'), -0.08242941372327217),\n",
      " (('capital-gain', 'education-num'), -0.10945060411861184),\n",
      " (('education-num', 'occupation'), -0.15552817179941655),\n",
      " (('age', 'occupation'), -0.18721213344357684),\n",
      " ('occupation', -0.22499415747477788),\n",
      " ('education-num', -0.27120647168322776)]\n",
      "Minority Factual Changes: \n",
      "Rank 1 | ('capital-loss', 'education-num') (PreCoF: 0.1939): [((0.0, 13.0), 1000), ((0.0, 9.0), 905)]\n",
      "Rank 2 | ('marital-status', 'occupation') (PreCoF: 0.1006): [((0.0, 1.0), 207), ((4.0, 1.0), 104)]\n",
      "Rank 3 | ('age', 'capital-loss') (PreCoF: 0.0999): [((23.0, 0.0), 51), ((24.0, 0.0), 42)]\n",
      "Rank -3 | ('age', 'occupation') (PreCoF: -0.1872): [((31.0, 1.0), 7), ((32.0, 1.0), 6)]\n",
      "Rank -2 | occupation (PreCoF: -0.2250): [(1.0, 59), (10.0, 50)]\n",
      "Rank -1 | education-num (PreCoF: -0.2712): [(13.0, 177), (9.0, 146)]\n",
      "Minority Explanation Changes: \n",
      "Rank 1 | ('capital-loss', 'education-num') (PreCoF: 0.1939): [(('capital-loss > 5.67', 'education-num > 0.94'), 1607), (('capital-loss > 5.73', 'education-num <= 0.94'), 691)]\n",
      "Rank 2 | ('marital-status', 'occupation') (PreCoF: 0.1006): [(('marital-status_2 > 0.50', 'occupation_4 > 0.50'), 883), (('marital-status_2 > 0.50', 'occupation_13 > 0.50'), 184)]\n",
      "Rank 3 | ('age', 'capital-loss') (PreCoF: 0.0999): [(('age <= 1.08', 'capital-loss > 5.73'), 474), (('age > -0.67', 'capital-loss > 5.67'), 215)]\n",
      "Rank -3 | ('age', 'occupation') (PreCoF: -0.1872): [(('age <= -0.60', 'occupation_13 > 0.50'), 155), (('age > 0.06', 'occupation_4 > 0.50'), 41)]\n",
      "Rank -2 | occupation (PreCoF: -0.2250): [('occupation_4 > 0.50', 197), ('occupation_13 > 0.50', 34)]\n",
      "Rank -1 | education-num (PreCoF: -0.2712): [('education-num > 0.55', 254), ('education-num > 1.72', 230)]\n",
      "Majority Factual Changes: \n",
      "Rank 1 | ('capital-loss', 'education-num') (PreCoF: 0.1939): [((0.0, 9.0), 1074), ((0.0, 13.0), 944)]\n",
      "Rank 2 | ('marital-status', 'occupation') (PreCoF: 0.1006): [((0.0, 3.0), 116), ((4.0, 3.0), 114)]\n",
      "Rank 3 | ('age', 'capital-loss') (PreCoF: 0.0999): [((24.0, 0.0), 45), ((23.0, 0.0), 40)]\n",
      "Rank -3 | ('age', 'occupation') (PreCoF: -0.1872): [((31.0, 3.0), 52), ((32.0, 3.0), 48)]\n",
      "Rank -2 | occupation (PreCoF: -0.2250): [(3.0, 587), (12.0, 246)]\n",
      "Rank -1 | education-num (PreCoF: -0.2712): [(9.0, 1248), (10.0, 696)]\n",
      "Majority Explanation Changes: \n",
      "Rank 1 | ('capital-loss', 'education-num') (PreCoF: 0.1939): [(('capital-loss > 5.67', 'education-num > 0.94'), 1019), (('capital-loss > 4.22', 'education-num > 0.55'), 867)]\n",
      "Rank 2 | ('marital-status', 'occupation') (PreCoF: 0.1006): [(('marital-status_2 > 0.50', 'occupation_4 > 0.50'), 769), (('marital-status_2 > 0.50', 'occupation_13 > 0.50'), 248)]\n",
      "Rank 3 | ('age', 'capital-loss') (PreCoF: 0.0999): [(('age <= 1.08', 'capital-loss > 5.73'), 225), (('age > -0.67', 'capital-loss > 5.67'), 199)]\n",
      "Rank -3 | ('age', 'occupation') (PreCoF: -0.1872): [(('age <= -0.60', 'occupation_13 > 0.50'), 1443), (('age > -0.45', 'occupation_4 > 0.50'), 146)]\n",
      "Rank -2 | occupation (PreCoF: -0.2250): [('occupation_4 > 0.50', 1743), ('occupation_13 > 0.50', 214)]\n",
      "Rank -1 | education-num (PreCoF: -0.2712): [('education-num > 0.55', 2516), ('education-num > 1.72', 239)]\n"
     ]
    }
   ],
   "source": [
    "adult = fetch_data('adult')\n",
    "X = adult.drop(columns=['target', 'fnlwgt', 'native-country'])\n",
    "y = adult.loc[:, 'target']\n",
    "\n",
    "cat = ['workclass','education','marital-status','occupation','relationship','race']\n",
    "X[cat] = X[cat].astype('category')\n",
    "\n",
    "precof_analysis(X, y, ['sex'], 'sex', 0, 1, 'adult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'juv_fel_count', 'decile_score', 'juv_misd_count',\n",
      "       'juv_other_count', 'priors_count'],\n",
      "      dtype='object') Index(['sex', 'age_cat', 'c_charge_desc'], dtype='object')\n",
      "get_counterfactual_counts_descriptive took 20.6183 seconds\n",
      "get_counterfactual_counts_descriptive took 12.6389 seconds\n",
      "get_precof_values took 33.2742 seconds\n",
      "\n",
      "Model without sensitive attributes\n",
      "=======================\n",
      "Classifier Accuracy: 0.8399\n",
      "\n",
      "Multi-Variable PreCoF Values:\n",
      "[(('c_charge_desc', 'juv_other_count'), 0.1530288577638252),\n",
      " (('c_charge_desc', 'juv_misd_count'), 0.11724402318280608),\n",
      " (('juv_other_count', 'priors_count'), 0.09545761893262494),\n",
      " (('decile_score', 'priors_count'), 0.0895792079207921),\n",
      " (('c_charge_desc', 'juv_fel_count'), 0.08101907751750786),\n",
      " (('age', 'juv_other_count'), 0.07528797391934317),\n",
      " (('c_charge_desc', 'priors_count'), 0.06666566046848588),\n",
      " (('juv_fel_count', 'priors_count'), 0.058307172180632694),\n",
      " (('age', 'priors_count'), 0.057534411977783195),\n",
      " (('decile_score', 'juv_misd_count'), 0.05389157208403769),\n",
      " (('c_charge_desc', 'c_charge_desc'), 0.04894107703453274),\n",
      " (('priors_count', 'sex'), 0.04886259357643083),\n",
      " (('age_cat', 'priors_count'), 0.04628773243177978),\n",
      " (('c_charge_desc', 'decile_score'), 0.044689688481043266),\n",
      " (('juv_misd_count', 'juv_other_count'), 0.04408596957256701),\n",
      " ('juv_misd_count', 0.043734001448925364),\n",
      " ('juv_other_count', 0.04172663607824195),\n",
      " ('juv_fel_count', 0.039258029461482734),\n",
      " (('age', 'juv_misd_count'), 0.03849915479352814),\n",
      " (('age', 'juv_fel_count'), 0.035455807775899545),\n",
      " (('age_cat', 'juv_other_count'), 0.03459188601787008),\n",
      " (('age', 'age_cat'), 0.03421275054334701),\n",
      " (('juv_misd_count', 'priors_count'), 0.03061035981646948),\n",
      " (('age_cat', 'c_charge_desc'), 0.025252958222651528),\n",
      " (('age', 'c_charge_desc'), 0.021692827819367322),\n",
      " (('decile_score', 'juv_fel_count'), 0.01633965225790871),\n",
      " (('age_cat', 'decile_score'), 0.014817676889640183),\n",
      " (('age_cat', 'juv_fel_count'), 0.014399903404974646),\n",
      " (('juv_other_count', 'sex'), 0.007068944699347984),\n",
      " (('juv_fel_count', 'juv_other_count'), 0.005903767205988892),\n",
      " (('age_cat', 'juv_misd_count'), 0.0049504950495049506),\n",
      " (('age_cat', 'sex'), 0.002452909925138855),\n",
      " (('decile_score', 'juv_other_count'), -0.0003912098526925867),\n",
      " (('age', 'decile_score'), -0.000884448200917709),\n",
      " (('juv_fel_count', 'juv_misd_count'), -0.0016892055059164453),\n",
      " (('juv_misd_count', 'sex'), -0.004064235691861869),\n",
      " (('juv_fel_count', 'sex'), -0.004281574498913306),\n",
      " ('age_cat', -0.012432383482250661),\n",
      " ('c_charge_desc', -0.0140485390002415),\n",
      " ('decile_score', -0.022733035498671783),\n",
      " ('priors_count', -0.025632697416083094),\n",
      " (('c_charge_desc', 'sex'), -0.032385897126298),\n",
      " ('age', -0.043555904370924936),\n",
      " (('decile_score', 'sex'), -0.043685703936247294),\n",
      " (('age', 'sex'), -0.061754407148031876),\n",
      " ('sex', -0.09445182323110363)]\n",
      "Minority Factual Changes: \n",
      "Rank 1 | ('c_charge_desc', 'juv_other_count') (PreCoF: 0.1530): [(('arrest case no charge', 0), 191), (('Possession of Cocaine', 0), 165)]\n",
      "Rank 2 | ('c_charge_desc', 'juv_misd_count') (PreCoF: 0.1172): [(('Possession of Cocaine', 0), 139), (('Grand Theft in the 3rd Degree', 0), 92)]\n",
      "Rank 3 | ('juv_other_count', 'priors_count') (PreCoF: 0.0955): [((0, 0), 75), ((0, 1), 67)]\n",
      "Rank -3 | ('decile_score', 'sex') (PreCoF: -0.0437): [((6, 'Male'), 42), ((8, 'Male'), 36)]\n",
      "Rank -2 | ('age', 'sex') (PreCoF: -0.0618): [((21, 'Male'), 41), ((26, 'Male'), 27)]\n",
      "Rank -1 | sex (PreCoF: -0.0945): [('Male', 413), ('Female', 65)]\n",
      "Minority Explanation Changes: \n",
      "Rank 1 | ('c_charge_desc', 'juv_other_count') (PreCoF: 0.1530): [(('c_charge_desc_Battery on Law Enforc Officer > 0.50', 'juv_other_count > 0.74'), 137), (('c_charge_desc_Deliver Cocaine > 0.50', 'juv_other_count > 0.74'), 119)]\n",
      "Rank 2 | ('c_charge_desc', 'juv_misd_count') (PreCoF: 0.1172): [(('c_charge_desc_Possession of Benzylpiperazine > 0.50', 'juv_misd_count > 2.88'), 283), (('c_charge_desc_False Imprisonment > 0.50', 'juv_misd_count > 2.88'), 283)]\n",
      "Rank 3 | ('juv_other_count', 'priors_count') (PreCoF: 0.0955): [(('juv_other_count > 19.19', 'priors_count <= 0.49'), 131), (('juv_other_count > 2.68', 'priors_count <= 0.49'), 123)]\n",
      "Rank -3 | ('decile_score', 'sex') (PreCoF: -0.0437): [(('decile_score <= 0.86', 'sex_Female > 0.50'), 43), (('decile_score <= -0.85', 'sex_Male <= 0.50'), 19)]\n",
      "Rank -2 | ('age', 'sex') (PreCoF: -0.0618): [(('age <= -0.99', 'sex_Female > 0.50'), 71), (('age > -0.99', 'sex_Male <= 0.50'), 48)]\n",
      "Rank -1 | sex (PreCoF: -0.0945): [('sex_Female > 0.50', 232), ('sex_Male <= 0.50', 181)]\n",
      "Majority Factual Changes: \n",
      "Rank 1 | ('c_charge_desc', 'juv_other_count') (PreCoF: 0.1530): [(('Possession of Cocaine', 0), 61), (('arrest case no charge', 0), 54)]\n",
      "Rank 2 | ('c_charge_desc', 'juv_misd_count') (PreCoF: 0.1172): [(('Possession of Cocaine', 0), 62), (('Battery', 0), 59)]\n",
      "Rank 3 | ('juv_other_count', 'priors_count') (PreCoF: 0.0955): [((0, 0), 32), ((0, 7), 28)]\n",
      "Rank -3 | ('decile_score', 'sex') (PreCoF: -0.0437): [((6, 'Male'), 33), ((3, 'Male'), 29)]\n",
      "Rank -2 | ('age', 'sex') (PreCoF: -0.0618): [((31, 'Male'), 33), ((21, 'Male'), 20)]\n",
      "Rank -1 | sex (PreCoF: -0.0945): [('Male', 329), ('Female', 71)]\n",
      "Majority Explanation Changes: \n",
      "Rank 1 | ('c_charge_desc', 'juv_other_count') (PreCoF: 0.1530): [(('c_charge_desc_Battery on Law Enforc Officer > 0.50', 'juv_other_count > 0.74'), 54), (('c_charge_desc_arrest case no charge > 0.50', 'juv_other_count > 4.62'), 44)]\n",
      "Rank 2 | ('c_charge_desc', 'juv_misd_count') (PreCoF: 0.1172): [(('c_charge_desc_Possession of Benzylpiperazine > 0.50', 'juv_misd_count > 2.88'), 139), (('c_charge_desc_False Imprisonment > 0.50', 'juv_misd_count > 2.88'), 139)]\n",
      "Rank 3 | ('juv_other_count', 'priors_count') (PreCoF: 0.0955): [(('juv_other_count > 19.19', 'priors_count <= 0.49'), 41), (('juv_other_count > 0.74', 'priors_count <= 0.68'), 32)]\n",
      "Rank -3 | ('decile_score', 'sex') (PreCoF: -0.0437): [(('decile_score > -0.16', 'sex_Female > 0.50'), 28), (('decile_score <= 0.86', 'sex_Female > 0.50'), 20)]\n",
      "Rank -2 | ('age', 'sex') (PreCoF: -0.0618): [(('age <= -0.99', 'sex_Female > 0.50'), 87), (('age > -0.99', 'sex_Male <= 0.50'), 21)]\n",
      "Rank -1 | sex (PreCoF: -0.0945): [('sex_Female > 0.50', 170), ('sex_Male <= 0.50', 159)]\n"
     ]
    }
   ],
   "source": [
    "compas=pd.read_csv('DATA/cox-violent-parsed.csv')\n",
    "compas['race'] = compas['race'].replace('African-American', 'African_American')\n",
    "compas['race'] = compas['race'].replace('Native American', 'Native_American')\n",
    "\n",
    "X=compas[['sex','age','age_cat', 'race', 'juv_fel_count','decile_score', 'juv_misd_count','juv_other_count', 'priors_count', 'c_charge_desc']]\n",
    "y=compas['is_recid'].replace(-1, 0)\n",
    "\n",
    "precof_analysis(X, y, ['race'], 'race', 'African_American', 1, 'compas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_recid                              0   1\n",
      "race             juv_other_category        \n",
      "African_American high                 7   2\n",
      "                 low                 20  43\n",
      "Caucasian        high                 1   1\n",
      "                 low                 27  15\n",
      "Hispanic         high                 0   3\n",
      "                 low                  5  14\n",
      "Native_American  low                  3   0\n",
      "Other            low                  0   3\n"
     ]
    }
   ],
   "source": [
    "filtered_compas = compas[\n",
    "    (compas['c_charge_desc'] == 'Battery on Law Enforc Officer') \n",
    "].copy()\n",
    "\n",
    "median_juv_other_count = compas['juv_other_count'].median()\n",
    "filtered_compas['juv_other_category'] = filtered_compas['juv_other_count'].apply(\n",
    "    lambda x: 'high' if x > median_juv_other_count else 'low'\n",
    ")\n",
    "\n",
    "\n",
    "print(filtered_compas.groupby(['race', 'juv_other_category', 'is_recid']).size().unstack(fill_value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age_final'], dtype='object') Index(['sex', 'national_group', 'age_group', 'province', 'prior_crime',\n",
      "       'prior_crimerec', 'prior_crimes', 'crime_maincat', 'crime_violence',\n",
      "       'crime_type', 'past_supervision_failure', 'history_self_harm',\n",
      "       'violent_home', 'childhood_mistreatment', 'parental_criminality',\n",
      "       'poor_school', 'delinquent_peer_group', 'rejected_by_peer_group',\n",
      "       'lack_of_social_support', 'community_disorganization'],\n",
      "      dtype='object')\n",
      "get_counterfactual_counts_descriptive took 0.0326 seconds\n",
      "get_counterfactual_counts_descriptive took 0.0490 seconds\n",
      "get_precof_values took 0.0886 seconds\n",
      "\n",
      "Model without sensitive attributes\n",
      "=======================\n",
      "Classifier Accuracy: 0.6732\n",
      "\n",
      "Multi-Variable PreCoF Values:\n",
      "[('age_final', 0.20606060606060606),\n",
      " ('delinquent_peer_group', 0.19797979797979798),\n",
      " (('age_final', 'prior_crimerec'), 0.11313131313131314),\n",
      " (('prior_crimerec', 'province'), 0.06868686868686869),\n",
      " (('delinquent_peer_group', 'prior_crimerec'), 0.05656565656565657),\n",
      " (('age_final', 'province'), 0.03838383838383838),\n",
      " (('age_final', 'poor_school'), 0.03838383838383838),\n",
      " (('poor_school', 'prior_crimerec'), 0.01010101010101011),\n",
      " ('past_supervision_failure', 0.0020202020202020193),\n",
      " (('community_disorganization', 'prior_crimerec'), -0.006060606060606058),\n",
      " (('community_disorganization', 'violent_home'), -0.006060606060606058),\n",
      " (('prior_crimerec', 'violent_home'), -0.014141414141414142),\n",
      " (('past_supervision_failure', 'violent_home'), -0.020202020202020193),\n",
      " (('delinquent_peer_group', 'poor_school'), -0.022222222222222223),\n",
      " (('delinquent_peer_group', 'lack_of_social_support'), -0.022222222222222223),\n",
      " (('age_final', 'violent_home'), -0.028282828282828285),\n",
      " (('age_final', 'community_disorganization'), -0.04242424242424242),\n",
      " (('age_final', 'past_supervision_failure'), -0.044444444444444446),\n",
      " (('lack_of_social_support', 'prior_crimerec'), -0.05858585858585859),\n",
      " ('lack_of_social_support', -0.08686868686868687),\n",
      " (('community_disorganization', 'community_disorganization'),\n",
      "  -0.10303030303030303),\n",
      " ('violent_home', -0.1090909090909091),\n",
      " ('province', -0.12525252525252525),\n",
      " ('community_disorganization', -0.1292929292929293),\n",
      " ('prior_crimerec', -0.13131313131313133),\n",
      " (('community_disorganization', 'poor_school'), -0.1696969696969697),\n",
      " (('community_disorganization', 'province'), -0.1696969696969697),\n",
      " ('poor_school', -0.2121212121212121)]\n",
      "Minority Factual Changes: \n",
      "Rank 1 | age_final (PreCoF: 0.2061): [(16, 9), (17, 6)]\n",
      "Rank 2 | delinquent_peer_group (PreCoF: 0.1980): [('Alt', 8)]\n",
      "Rank 3 | ('age_final', 'prior_crimerec') (PreCoF: 0.1131): [((16, 'Més de 5 antecedents'), 3), ((16, '1 o 2 antecedents'), 3)]\n",
      "Rank -3 | ('community_disorganization', 'poor_school') (PreCoF: -0.1697): [(('Moderat', 'Alt'), 1)]\n",
      "Rank -2 | ('community_disorganization', 'province') (PreCoF: -0.1697): [(('Moderat', 'Barcelona'), 1)]\n",
      "Rank -1 | poor_school (PreCoF: -0.2121): [('Alt', 4)]\n",
      "Minority Explanation Changes: \n",
      "Rank 1 | age_final (PreCoF: 0.2061): [('age_final > -0.26', 11), ('age_final > -1.02', 9)]\n",
      "Rank 2 | delinquent_peer_group (PreCoF: 0.1980): [('delinquent_peer_group_Alt <= 0.50', 8)]\n",
      "Rank 3 | ('age_final', 'prior_crimerec') (PreCoF: 0.1131): [(('age_final > -0.26', 'prior_crimerec_1 o 2 antecedents > 0.50'), 10), (('age_final > -1.02', 'prior_crimerec_1 o 2 antecedents <= 0.50'), 4)]\n",
      "Rank -3 | ('community_disorganization', 'poor_school') (PreCoF: -0.1697): [(('community_disorganization_Baix > 0.50', 'poor_school_Alt <= 0.50'), 1)]\n",
      "Rank -2 | ('community_disorganization', 'province') (PreCoF: -0.1697): [(('community_disorganization_Baix > 0.50', 'province_Barcelona <= 0.50'), 1)]\n",
      "Rank -1 | poor_school (PreCoF: -0.2121): [('poor_school_Alt <= 0.50', 4)]\n",
      "Majority Factual Changes: \n",
      "Rank 1 | age_final (PreCoF: 0.2061): [(16, 10), (17, 6)]\n",
      "Rank 2 | delinquent_peer_group (PreCoF: 0.1980): [('Alt', 2)]\n",
      "Rank 3 | ('age_final', 'prior_crimerec') (PreCoF: 0.1131): [((17, 'De 3 a 5 antecedents'), 4), ((16, 'De 3 a 5 antecedents'), 3)]\n",
      "Rank -3 | ('community_disorganization', 'poor_school') (PreCoF: -0.1697): [(('Moderat', 'Alt'), 8), (('Alt', 'Alt'), 1)]\n",
      "Rank -2 | ('community_disorganization', 'province') (PreCoF: -0.1697): [(('Moderat', 'Barcelona'), 7), (('Moderat', nan), 1)]\n",
      "Rank -1 | poor_school (PreCoF: -0.2121): [('Alt', 15)]\n",
      "Majority Explanation Changes: \n",
      "Rank 1 | age_final (PreCoF: 0.2061): [('age_final > -0.26', 11), ('age_final > -1.02', 7)]\n",
      "Rank 2 | delinquent_peer_group (PreCoF: 0.1980): [('delinquent_peer_group_Alt <= 0.50', 2)]\n",
      "Rank 3 | ('age_final', 'prior_crimerec') (PreCoF: 0.1131): [(('age_final > -0.26', 'prior_crimerec_1 o 2 antecedents > 0.50'), 11), (('age_final > -1.02', 'prior_crimerec_1 o 2 antecedents <= 0.50'), 3)]\n",
      "Rank -3 | ('community_disorganization', 'poor_school') (PreCoF: -0.1697): [(('community_disorganization_Baix > 0.50', 'poor_school_Alt <= 0.50'), 9)]\n",
      "Rank -2 | ('community_disorganization', 'province') (PreCoF: -0.1697): [(('community_disorganization_Baix > 0.50', 'province_Barcelona <= 0.50'), 9)]\n",
      "Rank -1 | poor_school (PreCoF: -0.2121): [('poor_school_Alt <= 0.50', 15)]\n"
     ]
    }
   ],
   "source": [
    "dfmain = pd.read_csv(\"https://github.com/nkundiushuti/savry/blob/master/dat/reincidenciaJusticiaMenors.csv?raw=true\",low_memory=False)\n",
    "dfmain = dfmain.rename(index=str, columns={\"V2_estranger\": \"foreigner\", \"V1_sexe\": \"sex\",\"V60_SAVRY_total_score\": \"full_score\", \\\n",
    "                                  \"V115_reincidencia_2015\":'recid', \"V4_nacionalitat_agrupat\":\"national_group\", \\\n",
    "                                  \"V5_edat_fet_agrupat\":\"age_group\",\"V6_provincia\":\"province\",\"V9_edat_final_programa\": \\\n",
    "                                  \"age_final\", \"V11_antecedents\":\"prior_crime\", \"V12_nombre_ante_agrupat\": \\\n",
    "                                   \"prior_crimerec\",\"V13_nombre_fets_agrupat\": \"prior_crimes\", \"V15_fet_agrupat\": \\\n",
    "                                  \"crime_maincat\", \"V16_fet_violencia\": \"crime_violence\", \"V17_fet_tipus\":\"crime_type\", \\\n",
    "                                  'V68_@4_fracas_intervencions_anteriors':'past_supervision_failure','V69_@5_intents_autolesio_suicidi_anteriors':'history_self_harm',\\\n",
    "                                      'V70_@6_exposicio_violencia_llar':'violent_home','V71_@7_historia_maltracte_infantil':'childhood_mistreatment', 'V72_@8_delinquencia_pares':'parental_criminality',\\\n",
    "                                          'V74_@10_baix_rendiment_escola':'poor_school','V75_@11_delinquencia_grup_iguals':'delinquent_peer_group','V76_@12_rebuig_grup_iguals':'rejected_by_peer_group',\\\n",
    "                                              'V79_@15_manca_suport_personal_social':'lack_of_social_support','V80_@16_entorn_marginal':'community_disorganization'})\n",
    "dfmain['label_value'] = dfmain.recid == 'Sí'\n",
    "dfmain.national_group=dfmain.national_group.fillna('Spanish')\n",
    "dfaequi=dfmain[['id', 'recid','label_value','full_score','foreigner','sex','national_group','age_group','province','age_final', \\\n",
    "            'prior_crime','prior_crimerec','prior_crimes','crime_maincat','crime_violence', 'crime_type','past_supervision_failure','history_self_harm', 'violent_home',\\\n",
    "                'childhood_mistreatment','parental_criminality','poor_school', 'delinquent_peer_group','rejected_by_peer_group','lack_of_social_support','community_disorganization']]\n",
    "\n",
    "dfaequi = dfaequi[np.isfinite(dfaequi['full_score'])]\n",
    "dfaequi = dfaequi.loc[dfaequi['full_score'] != 99]\n",
    "dfaequi.age_group=dfaequi.age_group.fillna('16 i 17 anys')\n",
    "df = dfaequi\n",
    "\n",
    "X = df.drop(['full_score', 'id', 'label_value','recid'], axis=1)\n",
    "y = (df['label_value'])\n",
    "sensitive_attribute='foreigner'\n",
    "sensitive_value='Estranger'\n",
    "\n",
    "precof_analysis(X, y, [\"foreigner\"], \"foreigner\", \"Estranger\", True, 'catalonia')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['population', 'householdsize', 'agePct12t21', 'agePct12t29',\n",
      "       'agePct16t24', 'agePct65up', 'numbUrban', 'pctUrban', 'medIncome',\n",
      "       'pctWWage', 'pctWFarmSelf', 'pctWInvInc', 'pctWSocSec', 'pctWPubAsst',\n",
      "       'pctWRetire', 'medFamInc', 'perCapInc', 'NumUnderPov', 'PctPopUnderPov',\n",
      "       'PctLess9thGrade', 'PctNotHSGrad', 'PctBSorMore', 'PctUnemployed',\n",
      "       'PctEmploy', 'PctEmplManu', 'PctEmplProfServ', 'PctOccupManu',\n",
      "       'PctOccupMgmtProf', 'MalePctDivorce', 'MalePctNevMarr', 'FemalePctDiv',\n",
      "       'TotalPctDiv', 'PersPerFam', 'PctFam2Par', 'PctKids2Par',\n",
      "       'PctYoungKids2Par', 'PctTeen2Par', 'PctWorkMomYoungKids', 'PctWorkMom',\n",
      "       'NumIlleg', 'PctIlleg', 'NumImmig', 'PctImmigRecent', 'PctImmigRec5',\n",
      "       'PctImmigRec8', 'PctImmigRec10', 'PctRecentImmig', 'PctRecImmig5',\n",
      "       'PctRecImmig8', 'PctRecImmig10', 'PctSpeakEnglOnly',\n",
      "       'PctNotSpeakEnglWell', 'PctLargHouseFam', 'PctLargHouseOccup',\n",
      "       'PersPerOccupHous', 'PersPerOwnOccHous', 'PersPerRentOccHous',\n",
      "       'PctPersOwnOccup', 'PctPersDenseHous', 'PctHousLess3BR', 'MedNumBR',\n",
      "       'HousVacant', 'PctHousOccup', 'PctHousOwnOcc', 'PctVacantBoarded',\n",
      "       'PctVacMore6Mos', 'MedYrHousBuilt', 'PctHousNoPhone', 'PctWOFullPlumb',\n",
      "       'OwnOccLowQuart', 'OwnOccMedVal', 'OwnOccHiQuart', 'RentLowQ',\n",
      "       'RentMedian', 'RentHighQ', 'MedRent', 'MedRentPctHousInc',\n",
      "       'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg', 'NumInShelters',\n",
      "       'NumStreet', 'PctForeignBorn', 'PctBornSameState', 'PctSameHouse85',\n",
      "       'PctSameCity85', 'PctSameState85', 'LandArea', 'PopDens',\n",
      "       'PctUsePubTrans', 'LemasPctOfficDrugUn'],\n",
      "      dtype='object') Index([], dtype='object')\n",
      "Warning: no categorical features found\n",
      "get_counterfactual_counts_descriptive took 0.0102 seconds\n",
      "get_precof_values took 0.0154 seconds\n",
      "\n",
      "Model without sensitive attributes\n",
      "=======================\n",
      "Classifier Accuracy: 0.9549\n",
      "\n",
      "Multi-Variable PreCoF Values:\n",
      "[('PctBornSameState', 1.0), ('NumStreet', 1.0), ('PctFam2Par', 1.0)]\n",
      "Minority Factual Changes: \n",
      "Rank 1 | PctBornSameState (PreCoF: 1.0000): [(0.29, 1), (0.62, 1)]\n",
      "Rank 2 | NumStreet (PreCoF: 1.0000): [(0.01, 1), (0.06, 1)]\n",
      "Rank 3 | PctFam2Par (PreCoF: 1.0000): [(0.22, 2), (0.29, 2)]\n",
      "Rank -3 | PctBornSameState (PreCoF: 1.0000): [(0.29, 1), (0.62, 1)]\n",
      "Rank -2 | NumStreet (PreCoF: 1.0000): [(0.01, 1), (0.06, 1)]\n",
      "Rank -1 | PctFam2Par (PreCoF: 1.0000): [(0.22, 2), (0.29, 2)]\n",
      "Minority Explanation Changes: \n",
      "Rank 1 | PctBornSameState (PreCoF: 1.0000): [('PctBornSameState > 0.17', 12)]\n",
      "Rank 2 | NumStreet (PreCoF: 1.0000): [('NumStreet <= -0.18', 12)]\n",
      "Rank 3 | PctFam2Par (PreCoF: 1.0000): [('PctFam2Par > -1.50', 12)]\n",
      "Rank -3 | PctBornSameState (PreCoF: 1.0000): [('PctBornSameState > 0.17', 12)]\n",
      "Rank -2 | NumStreet (PreCoF: 1.0000): [('NumStreet <= -0.18', 12)]\n",
      "Rank -1 | PctFam2Par (PreCoF: 1.0000): [('PctFam2Par > -1.50', 12)]\n",
      "Majority Factual Changes: \n",
      "Majority Explanation Changes: \n"
     ]
    }
   ],
   "source": [
    "crime2 = pd.read_csv('DATA/fairness_dataset-main/fairness_dataset-main/experiments/data/communities_crime.csv', sep=',')\n",
    "X = crime2.drop(columns=['class','communityname','state', 'ViolentCrimesPerPop', 'racepctblack', 'racePctWhite', 'racePctAsian', 'racePctHisp', 'fold','AsianPerCap','HispPerCap','whitePerCap','blackPerCap','indianPerCap', 'HispPerCap'])\n",
    "y = crime2['class']\n",
    "\n",
    "precof_analysis(X, y, ['Black'], 'Black', 1, True, 'crime2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
